---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/charts/elasticsearch/templates/poddisruptionbudget.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: "elasticsearch-master-pdb"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: "elasticsearch-master"
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx-controller
data:
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/configmap.yaml
kind: ConfigMap
metadata:
  name: zeebe-dev-zeebe-cluster-helm
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
apiVersion: v1
data:
  startup.sh: |
    #!/usr/bin/env bash
    set -eux -o pipefail

    export ZEEBE_BROKER_NETWORK_ADVERTISEDHOST=${ZEEBE_BROKER_NETWORK_ADVERTISEDHOST:-$(hostname -f)}
    export ZEEBE_BROKER_CLUSTER_NODEID=${ZEEBE_BROKER_CLUSTER_NODEID:-${K8S_POD_NAME##*-}}

    # As the number of replicas or the DNS is not obtainable from the downward API yet,
    # defined them here based on conventions
    export ZEEBE_BROKER_CLUSTER_CLUSTERSIZE=${ZEEBE_BROKER_CLUSTER_CLUSTERSIZE:-1}
    contactPointPrefix=${K8S_POD_NAME%-*}
    contactPoints=${ZEEBE_BROKER_CLUSTER_INITIALCONTACTPOINTS:-""}
    if [[ -z "${contactPoints}" ]]; then
      for ((i=0; i<${ZEEBE_BROKER_CLUSTER_CLUSTERSIZE}; i++))
      do
        contactPoints="${contactPoints},${contactPointPrefix}-$i.$(hostname -d):26502"
      done

      export ZEEBE_BROKER_CLUSTER_INITIALCONTACTPOINTS="${contactPoints}"
    fi
    
    if [ "$(ls -A /exporters/)" ]; then
      mkdir /usr/local/zeebe/exporters/
      cp -a /exporters/*.jar /usr/local/zeebe/exporters/
    else  
      echo "No exporters available."
    fi

    exec /usr/local/zeebe/bin/broker

  application.yaml: |

  broker-log4j2.xml: |

  gateway-log4j2.xml: |
---
# Source: zeebe-full-helm/charts/zeebe-operate-helm/templates/configmap.yaml
kind: ConfigMap
metadata:
  name: zeebe-dev-zeebe-operate-helm
apiVersion: v1
data:
  application.yml: |
    # Operate configuration file
    camunda.operate:
      # ELS instance to store Operate data
      elasticsearch:
        # Cluster name
        clusterName: elasticsearch
        # Host
        host: elasticsearch-master
        # Transport port
        port: 9200
      # Zeebe instance
      zeebe:
        # Broker contact point
        brokerContactPoint: zeebe-dev-zeebe-gateway:26500
      # ELS instance to export Zeebe data to
      zeebeElasticsearch:
        # Cluster name
        clusterName: elasticsearch
        # Host
        host: elasticsearch-master
        # Transport port
        port: 9200
        # Index prefix, configured in Zeebe Elasticsearch exporter
        prefix: zeebe-record
    logging:
      level:
        ROOT: INFO
        org.camunda.operate: DEBUG
    #Spring Boot Actuator endpoints to be exposed
    management.endpoints.web.exposure.include: health,info,conditions,configprops,prometheus
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
  name: zeebe-dev-ingress-nginx
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups:
      - extensions
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  - apiGroups:
      - extensions
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
  name: zeebe-dev-ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: zeebe-dev-ingress-nginx
subjects:
  - kind: ServiceAccount
    name: zeebe-dev-ingress-nginx
    namespace: default
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - configmaps
      - pods
      - secrets
      - endpoints
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups:
      - extensions
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - "networking.k8s.io" # k8s 1.14+
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - ingress-controller-leader-nginx
    verbs:
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - endpoints
    verbs:
      - create
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: zeebe-dev-ingress-nginx
subjects:
  - kind: ServiceAccount
    name: zeebe-dev-ingress-nginx
    namespace: default
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-service-webhook.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx-controller-admission
spec:
  type: ClusterIP
  ports:
    - name: https-webhook
      port: 443
      targetPort: webhook
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/component: controller
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx-controller
spec:
  type: LoadBalancer
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/component: controller
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/charts/elasticsearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master
  labels:
    heritage: "Helm"
    release: "zeebe-dev"
    chart: "elasticsearch"
    app: "elasticsearch-master"
  annotations:
    {}
spec:
  type: ClusterIP
  selector:
    heritage: "Helm"
    release: "zeebe-dev"
    chart: "elasticsearch"
    app: "elasticsearch-master"
  ports:
  - name: http
    protocol: TCP
    port: 9200
  - name: transport
    protocol: TCP
    port: 9300
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/charts/elasticsearch/templates/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: elasticsearch-master-headless
  labels:
    heritage: "Helm"
    release: "zeebe-dev"
    chart: "elasticsearch"
    app: "elasticsearch-master"
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  clusterIP: None # This is needed for statefulset hostnames like elasticsearch-0 to resolve
  # Create endpoints also if the related pod isn't ready
  publishNotReadyAddresses: true
  selector:
    app: "elasticsearch-master"
  ports:
  - name: http
    port: 9200
  - name: transport
    port: 9300
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/gateway-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: "zeebe-dev-zeebe-gateway"
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: gateway
  annotations:
    null
spec:
  selector:
      app.kubernetes.io/name: zeebe-cluster-helm
      app.kubernetes.io/instance: zeebe-dev
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/component: gateway
  ports:
    - port: 9600
      protocol: TCP
      name: http
    - port: 26500
      protocol: TCP
      name: gateway
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: "zeebe-dev-zeebe"
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
    app: zeebe
  annotations:
    null    
spec:
  clusterIP: None
  publishNotReadyAddresses: true
  type: ClusterIP
  ports:
    - port: 9600
      protocol: TCP
      name: http  
    - port: 26502
      protocol: TCP
      name: internal
    - port: 26501
      protocol: TCP
      name: command
  selector:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
---
# Source: zeebe-full-helm/charts/zeebe-operate-helm/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: zeebe-dev-zeebe-operate-helm
  labels:
    app: zeebe-dev-zeebe-operate-helm
spec:
  type: ClusterIP
  ports:
  - port: 80
    name: http
    targetPort: 8080
    protocol: TCP
  selector:
    app: zeebe-dev-zeebe-operate-helm
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: zeebe-dev-ingress-nginx-controller
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/instance: zeebe-dev
      app.kubernetes.io/component: controller
  replicas: 1
  revisionHistoryLimit: 10
  minReadySeconds: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: zeebe-dev
        app.kubernetes.io/component: controller
    spec:
      dnsPolicy: ClusterFirst
      containers:
        - name: controller
          image: "k8s.gcr.io/ingress-nginx/controller:v0.43.0@sha256:9bba603b99bf25f6d117cf1235b6598c16033ad027b143c90fa5b3cc583c5713"
          imagePullPolicy: IfNotPresent
          lifecycle: 
            preStop:
              exec:
                command:
                - /wait-shutdown
          args:
            - /nginx-ingress-controller
            - --publish-service=$(POD_NAMESPACE)/zeebe-dev-ingress-nginx-controller
            - --election-id=ingress-controller-leader
            - --ingress-class=nginx
            - --configmap=$(POD_NAMESPACE)/zeebe-dev-ingress-nginx-controller
            - --validating-webhook=:8443
            - --validating-webhook-certificate=/usr/local/certificates/cert
            - --validating-webhook-key=/usr/local/certificates/key
          securityContext:
            capabilities:
                drop:
                - ALL
                add:
                - NET_BIND_SERVICE
            runAsUser: 101
            allowPrivilegeEscalation: true
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LD_PRELOAD
              value: /usr/local/lib/libmimalloc.so
          livenessProbe:
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - name: https
              containerPort: 443
              protocol: TCP
            - name: webhook
              containerPort: 8443
              protocol: TCP
          volumeMounts:
            - name: webhook-cert
              mountPath: /usr/local/certificates/
              readOnly: true
          resources: 
            requests:
              cpu: 100m
              memory: 90Mi
      nodeSelector: 
        kubernetes.io/os: linux
      serviceAccountName: zeebe-dev-ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
        - name: webhook-cert
          secret:
            secretName: zeebe-dev-ingress-nginx-admission
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "zeebe-dev-zeebe-gateway"
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: gateway
  annotations:
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zeebe-cluster-helm
      app.kubernetes.io/instance: zeebe-dev
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/component: gateway
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zeebe-cluster-helm
        app.kubernetes.io/instance: zeebe-dev
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: gateway
      annotations:
    spec:
      containers:
        - name: zeebe-cluster-helm
          image: "camunda/zeebe:0.26.0"
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9600
              name: http
            - containerPort: 26500
              name: gateway
            - containerPort: 26502
              name: internal
          env:
            - name: ZEEBE_STANDALONE_GATEWAY
              value: "true"
            - name: ZEEBE_GATEWAY_CLUSTER_CLUSTERNAME
              value: zeebe-dev-zeebe
            - name: ZEEBE_GATEWAY_CLUSTER_MEMBERID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: ZEEBE_LOG_LEVEL
              value: "info"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:MaxRAMPercentage=25.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/zeebe/data -XX:ErrorFile=/usr/local/zeebe/data/zeebe_error%p.log -XX:+ExitOnOutOfMemoryError"
            - name: ZEEBE_GATEWAY_CLUSTER_CONTACTPOINT
              value: zeebe-dev-zeebe:26502
            - name: ZEEBE_GATEWAY_NETWORK_HOST
              value: 0.0.0.0
            - name: ZEEBE_GATEWAY_NETWORK_PORT
              value: "26500"
            - name: ZEEBE_GATEWAY_CLUSTER_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: ZEEBE_GATEWAY_CLUSTER_PORT
              value: "26502"
            - name: ZEEBE_GATEWAY_MONITORING_HOST
              value: 0.0.0.0
            - name: ZEEBE_GATEWAY_MONITORING_PORT
              value: "9600"
          volumeMounts:
          securityContext:
            null
          readinessProbe:
            tcpSocket:
              port: gateway
            initialDelaySeconds: 20
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: zeebe-dev-zeebe-cluster-helm
            defaultMode: 0744
---
# Source: zeebe-full-helm/charts/zeebe-operate-helm/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zeebe-dev-zeebe-operate-helm
  labels:
    app: zeebe-dev-zeebe-operate-helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zeebe-dev-zeebe-operate-helm
  template:
    metadata:
      labels:
        app: zeebe-dev-zeebe-operate-helm
    spec:
      containers:
      - name: zeebe-operate-helm
        image: "camunda/operate:0.26.0"
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 768Mi
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        volumeMounts:
        - name: config
          mountPath: /usr/local/operate/config/application.yml
          subPath: application.yml
      volumes:
      - name: config
        configMap:
          name: zeebe-dev-zeebe-operate-helm
          defaultMode: 0744
      securityContext:
        null
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/charts/elasticsearch/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch-master
  labels:
    heritage: "Helm"
    release: "zeebe-dev"
    chart: "elasticsearch"
    app: "elasticsearch-master"
    app: "zeebe"
  annotations:
    esMajorVersion: "6"
spec:
  serviceName: elasticsearch-master-headless
  selector:
    matchLabels:
      app: "elasticsearch-master"
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-master
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 100M
  template:
    metadata:
      name: "elasticsearch-master"
      labels:
        heritage: "Helm"
        release: "zeebe-dev"
        chart: "elasticsearch"
        app: "elasticsearch-master"
        app: "zeebe"
        app: "elasticsearch-master"
      annotations:
        
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - "elasticsearch-master"
      terminationGracePeriodSeconds: 120
      volumes:
      initContainers:
      - name: configure-sysctl
        securityContext:
          runAsUser: 0
          privileged: true
        image: "docker.elastic.co/elasticsearch/elasticsearch:6.8.5"
        imagePullPolicy: "IfNotPresent"
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        resources:
          {}

      containers:
      - name: "elasticsearch"
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        image: "docker.elastic.co/elasticsearch/elasticsearch:6.8.5"
        imagePullPolicy: "IfNotPresent"
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 3
          timeoutSeconds: 5
          exec:
            command:
              - sh
              - -c
              - |
                #!/usr/bin/env bash -e
                # If the node is starting up wait for the cluster to be ready (request params: 'wait_for_status=yellow&timeout=1s' )
                # Once it has started only check that the node itself is responding
                START_FILE=/tmp/.es_start_file

                http () {
                    local path="${1}"
                    if [ -n "${ELASTIC_USERNAME}" ] && [ -n "${ELASTIC_PASSWORD}" ]; then
                      BASIC_AUTH="-u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD}"
                    else
                      BASIC_AUTH=''
                    fi
                    curl -XGET -s -k --fail ${BASIC_AUTH} http://127.0.0.1:9200${path}
                }

                if [ -f "${START_FILE}" ]; then
                    echo 'Elasticsearch is already running, lets check the node is healthy and there are master nodes available'
                    http "/_cluster/health?timeout=0s"
                else
                    echo 'Waiting for elasticsearch cluster to become cluster to be ready (request params: "wait_for_status=yellow&timeout=1s" )'
                    if http "/_cluster/health?wait_for_status=yellow&timeout=1s" ; then
                        touch ${START_FILE}
                        exit 0
                    else
                        echo 'Cluster is not yet ready (request params: "wait_for_status=yellow&timeout=1s" )'
                        exit 1
                    fi
                fi
        ports:
        - name: http
          containerPort: 9200
        - name: transport
          containerPort: 9300
        resources:
          limits:
            cpu: 1000m
            memory: 512M
          requests:
            cpu: 100m
            memory: 512M
        env:
          - name: node.name
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: discovery.zen.minimum_master_nodes
            value: "1"
          - name: discovery.zen.ping.unicast.hosts
            value: "elasticsearch-master-headless"
          - name: cluster.name
            value: "elasticsearch"
          - name: network.host
            value: "0.0.0.0"
          - name: ES_JAVA_OPTS
            value: "-Xmx128m -Xms128m"
          - name: node.data
            value: "true"
          - name: node.ingest
            value: "true"
          - name: node.master
            value: "true"
        volumeMounts:
          - name: "elasticsearch-master"
            mountPath: /usr/share/elasticsearch/data
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "zeebe-dev-zeebe"
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
    app: zeebe
  annotations:   
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: zeebe-cluster-helm
      app.kubernetes.io/instance: zeebe-dev
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/component: broker
  serviceName: "zeebe-dev-zeebe"
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: Parallel
  template:
    metadata:
      labels:
        app.kubernetes.io/name: zeebe-cluster-helm
        app.kubernetes.io/instance: zeebe-dev
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: broker
      annotations:   
    spec:
      initContainers:    
      containers:
      - name: zeebe-cluster-helm
        image: "camunda/zeebe:0.26.0"
        imagePullPolicy: IfNotPresent
        env:
        - name: ZEEBE_BROKER_CLUSTER_CLUSTERNAME
          value: zeebe-dev-zeebe
        - name: ZEEBE_LOG_LEVEL
          value: "info"
        - name: ZEEBE_BROKER_CLUSTER_PARTITIONSCOUNT
          value: "1"
        - name: ZEEBE_BROKER_CLUSTER_CLUSTERSIZE
          value: "1"
        - name: ZEEBE_BROKER_CLUSTER_REPLICATIONFACTOR
          value: "1"
        - name: ZEEBE_BROKER_THREADS_CPUTHREADCOUNT
          value: "2"
        - name: ZEEBE_BROKER_THREADS_IOTHREADCOUNT
          value: "2"
        - name: ZEEBE_BROKER_GATEWAY_ENABLE
          value: "false"
        - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME
          value: "io.zeebe.exporter.ElasticsearchExporter"
        - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL
          value: "http://elasticsearch-master:9200"
        - name: ZEEBE_BROKER_NETWORK_COMMANDAPI_PORT
          value: "26501"
        - name: ZEEBE_BROKER_NETWORK_INTERNALAPI_PORT
          value: "26502"
        - name: ZEEBE_BROKER_NETWORK_MONITORINGAPI_PORT
          value: "9600"         
        - name: K8S_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name              
        - name: JAVA_TOOL_OPTIONS
          value: "-XX:MaxRAMPercentage=25.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/zeebe/data -XX:ErrorFile=/usr/local/zeebe/data/zeebe_error%p.log -XX:+ExitOnOutOfMemoryError"
        ports:
        - containerPort: 9600
          name: http
        - containerPort: 26501
          name: command
        - containerPort: 26502
          name: internal
        readinessProbe:
          httpGet:
            path: /ready
            port: 9600
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
            limits:
              cpu: 1000m
              memory: 4Gi
            requests:
              cpu: 500m
              memory: 2Gi
        volumeMounts:
        - name: config
          mountPath: /usr/local/zeebe/config/application.yaml
          subPath: application.yaml
        - name: config
          mountPath: /usr/local/bin/startup.sh
          subPath: startup.sh
        - name: data
          mountPath: /usr/local/zeebe/data
        - name: exporters
          mountPath: /exporters
        securityContext:
          null
      volumes:
      - name: config
        configMap:
          name: zeebe-dev-zeebe-cluster-helm
          defaultMode: 0744
      - name: exporters
        emptyDir: {}
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName: 
      resources:
        requests:
          storage: "10Gi"
---
# Source: zeebe-full-helm/charts/zeebe-operate-helm/templates/ingress.yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: zeebe-dev-zeebe-operate-helm
  labels: 
    app.kubernetes.io/name: zeebe-operate-helm
    helm.sh/chart: zeebe-operate-helm-0.0.39
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
  annotations: 
    ingress.kubernetes.io/rewrite-target: /
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
    - host: 
      http:
        paths:
          - path: /
            backend:
              serviceName: zeebe-dev-zeebe-operate-helm
              servicePort: 80
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/validating-webhook.yaml
# before changing this value, check the required kubernetes version
# https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
  name: zeebe-dev-ingress-nginx-admission
webhooks:
  - name: validate.nginx.ingress.kubernetes.io
    matchPolicy: Equivalent
    rules:
      - apiGroups:
          - networking.k8s.io
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - ingresses
    failurePolicy: Fail
    sideEffects: None
    admissionReviewVersions:
      - v1
      - v1beta1
    clientConfig:
      service:
        namespace: default
        name: zeebe-dev-ingress-nginx-controller-admission
        path: /networking/v1beta1/ingresses
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: zeebe-dev-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: zeebe-dev-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
    verbs:
      - get
      - update
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name:  zeebe-dev-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: zeebe-dev-ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: zeebe-dev-ingress-nginx-admission
    namespace: default
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name:  zeebe-dev-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: zeebe-dev-ingress-nginx-admission
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade,post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: zeebe-dev-ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: zeebe-dev-ingress-nginx-admission
    namespace: default
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/charts/elasticsearch/templates/test/test-elasticsearch-health.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "zeebe-dev-qmclw-test"
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
  - name: "zeebe-dev-ngoth-test"
    image: "docker.elastic.co/elasticsearch/elasticsearch:6.8.5"
    command:
      - "sh"
      - "-c"
      - |
        #!/usr/bin/env bash -e
        curl -XGET --fail 'elasticsearch-master:9200/_cluster/health?wait_for_status=yellow&timeout=1s'
  restartPolicy: Never
---
# Source: zeebe-full-helm/charts/zeebe-cluster-helm/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "zeebe-dev-zeebe-test-connection"
  labels:
    app.kubernetes.io/name: zeebe-cluster-helm
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args:  ['zeebe-dev-zeebe:9600']
  restartPolicy: Never
---
# Source: zeebe-full-helm/charts/zeebe-operate-helm/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "zeebe-dev-zeebe-operate-helm-test-connection"
  labels:
    app.kubernetes.io/name: zeebe-operate-helm
    helm.sh/chart: zeebe-operate-helm-0.0.39
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args:  ['zeebe-dev-zeebe-operate-helm:80']
  restartPolicy: Never
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: zeebe-dev-ingress-nginx-admission-create
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: zeebe-dev-ingress-nginx-admission-create
      labels:
        helm.sh/chart: ingress-nginx-3.19.0
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: zeebe-dev
        app.kubernetes.io/version: "0.43.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: create
          image: "docker.io/jettech/kube-webhook-certgen:v1.5.0"
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=zeebe-dev-ingress-nginx-controller-admission,zeebe-dev-ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
            - --namespace=$(POD_NAMESPACE)
            - --secret-name=zeebe-dev-ingress-nginx-admission
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      restartPolicy: OnFailure
      serviceAccountName: zeebe-dev-ingress-nginx-admission
      securityContext:
        runAsNonRoot: true
        runAsUser: 2000
---
# Source: zeebe-full-helm/charts/ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: zeebe-dev-ingress-nginx-admission-patch
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-3.19.0
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: zeebe-dev
    app.kubernetes.io/version: "0.43.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: zeebe-dev-ingress-nginx-admission-patch
      labels:
        helm.sh/chart: ingress-nginx-3.19.0
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: zeebe-dev
        app.kubernetes.io/version: "0.43.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: patch
          image: "docker.io/jettech/kube-webhook-certgen:v1.5.0"
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=zeebe-dev-ingress-nginx-admission
            - --namespace=$(POD_NAMESPACE)
            - --patch-mutating=false
            - --secret-name=zeebe-dev-ingress-nginx-admission
            - --patch-failure-policy=Fail
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      restartPolicy: OnFailure
      serviceAccountName: zeebe-dev-ingress-nginx-admission
      securityContext:
        runAsNonRoot: true
        runAsUser: 2000
